{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required Libraries\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import glob\n",
    "import skimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sn.set()\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from time import time\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score,f1_score,recall_score,cohen_kappa_score,precision_score\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelBinarizer, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNeighborsClassifier\n",
    "from sklearn.svm import SVC # SVM\n",
    "from sklearn.ensemble import RandomForestClassifier # RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier # AdaBoostClassifier\n",
    "from xgboost import XGBClassifier # XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications.vgg16 import VGG16 # VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19 # VGG19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50 # ResNet50\n",
    "from tensorflow.keras.applications import ResNet101 # ResNet 101\n",
    "from tensorflow.keras.applications.xception import Xception # Xception\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet # MobileNet\n",
    "from tensorflow.keras.applications.densenet import DenseNet169 # DenseNet169\n",
    "from tensorflow.keras.applications.densenet import DenseNet121 # DenseNet121\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 # MobileNetV2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 # InceptionV3\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Flatten, Activation, GlobalAveragePooling2D,Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(path):\n",
    "    '''\n",
    "        parameters\n",
    "        ----------\n",
    "        path : input path of the images\n",
    "        \n",
    "        returns\n",
    "        -------\n",
    "        loadedImages : list of loaded images \n",
    "    '''\n",
    "    sample = []\n",
    "    \n",
    "    for filename in glob.glob(path):\n",
    "        \n",
    "        img = cv2.imread(filename)\n",
    "        img = skimage.transform.resize(img, (224, 224, 3))\n",
    "        IMG = np.array(img)\n",
    "        sample.append(IMG)\n",
    "        \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path1 = 'train/NonDemented/*.jpg' \n",
    "train_path2 = 'train/VeryMildDemented/*.jpg'\n",
    "train_path3 = 'train/MildDemented/*.jpg'\n",
    "train_path4 = 'train/ModerateDemented/*.jpg'\n",
    "\n",
    "test_path1 = 'test/NonDemented/*.jpg' \n",
    "test_path2 = 'test/VeryMildDemented/*.jpg'\n",
    "test_path3 = 'test/MildDemented/*.jpg'\n",
    "test_path4 = 'test/ModerateDemented/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ND = loadImages(train_path1)\n",
    "train_VMD = loadImages(train_path2)\n",
    "train_MID = loadImages(train_path3)\n",
    "train_MOD = loadImages(train_path4)\n",
    "\n",
    "test_ND = loadImages(test_path1)\n",
    "test_VMD = loadImages(test_path2)\n",
    "test_MID = loadImages(test_path3)\n",
    "test_MOD = loadImages(test_path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% CREATION OF DATASETS\n",
    "\n",
    "df_train_ND = pd.DataFrame({'image':train_ND, 'label': 'ND'})\n",
    "df_train_VMD = pd.DataFrame({'image':train_VMD, 'label': 'VMD'})\n",
    "df_train_MID = pd.DataFrame({'image':train_MID, 'label': 'MID'})\n",
    "df_train_MOD = pd.DataFrame({'image':train_MOD, 'label': 'MOD'})\n",
    "\n",
    "df_test_ND = pd.DataFrame({'image':test_ND, 'label': 'ND'})\n",
    "df_test_VMD = pd.DataFrame({'image':test_VMD, 'label': 'VMD'})\n",
    "df_test_MID = pd.DataFrame({'image':test_MID, 'label': 'MID'})\n",
    "df_test_MOD = pd.DataFrame({'image':test_MOD, 'label': 'MOD'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire data size: (6400, 2)\n"
     ]
    }
   ],
   "source": [
    "final_data = [df_train_ND, df_train_VMD, df_train_MID, df_train_MOD, df_test_ND, df_test_VMD, df_test_MID, df_test_MOD]\n",
    "final_data = pd.concat(final_data)\n",
    "\n",
    "print(\"Entire data size:\",final_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% TRAIN LABEL SEPARATION\n",
    "\n",
    "train_data = final_data['image']\n",
    "labels = final_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels Count: Counter({'ND': 3200, 'VMD': 2240, 'MID': 896, 'MOD': 64})\n"
     ]
    }
   ],
   "source": [
    "#%% LOOKING AT THE AMOUNT OF ITEMS PER CLASS \n",
    "\n",
    "print(\"Labels Count:\",Counter(np.array(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#%% ENCODING THE LABELS\n",
    "onehot = LabelEncoder()\n",
    "labels = onehot.fit_transform(labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length X_train: 5120\n",
      "length y_train: 5120\n",
      "length X_test: 1280\n",
      "length y_test: 1280\n"
     ]
    }
   ],
   "source": [
    "#%% SPLITTING INTO TRAIN AND TEST SET, TRAIN SET WILL BE FURTHER SPLIT INTO TRAIN AND VALIDATION SET\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, labels,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  stratify = labels,\n",
    "                                                  shuffle = True,\n",
    "                                                  random_state = 42)\n",
    "\n",
    "print('length X_train:', len(X_train))\n",
    "print('length y_train:', len(y_train))\n",
    "\n",
    "print('length X_test:',  len(X_test))\n",
    "print('length y_test:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5120, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train= np.empty((len(X_train),X_train[0].shape[0],X_train[0].shape[1],X_train[0].shape[2]))\n",
    "for i,x in enumerate(X_train):\n",
    "    x_train[i]=X_train[i]\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "x_test= np.empty((len(X_test),X_test[0].shape[0],X_test[0].shape[1],X_test[0].shape[2]))\n",
    "for i,x in enumerate(X_test):\n",
    "    x_test[i]=X_test[i]\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x =  Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024,kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x =  Dropout(0.5)(x)\n",
    "x = Dense(1024,kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x =  Dropout(0.5)(x)\n",
    "x = Dense(1024,kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x =  Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model_feat = Model(inputs=base_model.input,outputs=predictions)\n",
    "\n",
    "train_features = model_feat.predict(x_train)\n",
    "test_features=model_feat.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Train and validation accuracy\n",
    "x_train_acc, x_val_acc, y_train_acc, y_val_acc = train_test_split(train_features,y_train,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  stratify = y_train,\n",
    "                                                  shuffle = True,\n",
    "                                                  random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length X_train: 4096\n",
      "length y_train: 4096\n",
      "length X_val: 1024\n",
      "length y_val: 1024\n",
      "length X_test: 1280\n",
      "length y_test: 1280\n"
     ]
    }
   ],
   "source": [
    "X_test,y_test=test_features,y_test\n",
    "\n",
    "print('length X_train:', len(x_train_acc))\n",
    "print('length y_train:', len(y_train_acc))\n",
    "\n",
    "print('length X_val:',  len(x_val_acc))\n",
    "print('length y_val:', len(y_val_acc))\n",
    "\n",
    "print('length X_test:',  len(X_test))\n",
    "print('length y_test:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n",
    "    sentiment_fit = pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train= sentiment_fit.predict(X_train)\n",
    "    y_pred_val = sentiment_fit.predict(X_val)\n",
    "    y_pred_test = sentiment_fit.predict(X_test)\n",
    "    \n",
    "    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n",
    "    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n",
    "    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n",
    "    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n",
    "    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n",
    "    train_confusion_matrix = confusion_matrix(y_train,y_pred_train)\n",
    "    \n",
    "    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n",
    "    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n",
    "    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n",
    "    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n",
    "    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n",
    "    val_confusion_matrix = confusion_matrix(y_val,y_pred_val)\n",
    "    \n",
    "    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n",
    "    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),4)\n",
    "    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),4)\n",
    "    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),4)\n",
    "    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),4) \n",
    "    test_confusion_matrix = confusion_matrix(y_test,y_pred_test)\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print('------------------------ Train Set Metrics------------------------')\n",
    "    print()\n",
    "    print(\"accuracy : {}%\".format(train_accuracy))\n",
    "    print(\"F1_score : {}\".format(train_F1))\n",
    "    print(\"Cohen Kappa Score : {} \".format(train_kappa))\n",
    "    print(\"Recall : {}\".format(train_recall))\n",
    "    print(\"Precision : {}\".format(train_precision))\n",
    "    print(\"Confusion Matrix :\\n {}\".format(train_confusion_matrix))\n",
    "    \n",
    "    print()\n",
    "    print('------------------------ Validation Set Metrics------------------------')\n",
    "    print()\n",
    "    print(\"accuracy : {}%\".format(val_accuracy))\n",
    "    print(\"F1_score : {}\".format(val_F1))\n",
    "    print(\"Cohen Kappa Score : {} \".format(val_kappa))\n",
    "    print(\"Recall : {}\".format(val_recall))\n",
    "    print(\"Precision : {}\".format(val_precision))\n",
    "    print(\"Confusion Matrix :\\n {}\".format(val_confusion_matrix))\n",
    "    \n",
    "    print()\n",
    "    print('------------------------ Test Set Metrics------------------------')\n",
    "    print()\n",
    "    print(\"accuracy : {}%\".format(test_accuracy))\n",
    "    print(\"F1_score : {}\".format(test_F1))\n",
    "    print(\"Cohen Kappa Score : {} \".format(test_kappa))\n",
    "    print(\"Recall : {}\".format(test_recall))\n",
    "    print(\"Precision : {}\".format(test_precision))\n",
    "    print(\"Confusion Matrix : {}\".format(test_confusion_matrix))\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "        \"K Nearest Neighbour Classifier\",\n",
    "        'SVM',\n",
    "        \"Random Forest Classifier\",\n",
    "        \"AdaBoost Classifier\", \n",
    "        \"XGB Classifier\",\n",
    "         ]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    SVC(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    XGBClassifier(),\n",
    "        ]\n",
    "\n",
    "zipped_clf = zip(names,classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n",
    "    result = []\n",
    "    for n,c in classifier:\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('classifier', c)\n",
    "        ])\n",
    "        print(\"Fitting {} on features \".format(n))\n",
    "        #print(c)\n",
    "        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting K Nearest Neighbour Classifier on features \n",
      "\n",
      "------------------------ Train Set Metrics------------------------\n",
      "\n",
      "accuracy : 60.35%\n",
      "F1_score : 0.5873\n",
      "Cohen Kappa Score : 0.315 \n",
      "Recall : 0.6035\n",
      "Precision : 0.5992\n",
      "Confusion Matrix :\n",
      " [[ 217    0  272   85]\n",
      " [   4    2   26    9]\n",
      " [ 149    1 1635  263]\n",
      " [ 113    2  700  618]]\n",
      "\n",
      "------------------------ Validation Set Metrics------------------------\n",
      "\n",
      "accuracy : 42.19%\n",
      "F1_score : 0.4044\n",
      "Cohen Kappa Score : 0.0117 \n",
      "Recall : 0.4219\n",
      "Precision : 0.3983\n",
      "Confusion Matrix :\n",
      " [[ 10   0  94  39]\n",
      " [  1   0   5   4]\n",
      " [ 64   0 325 123]\n",
      " [ 56   1 205  97]]\n",
      "\n",
      "------------------------ Test Set Metrics------------------------\n",
      "\n",
      "accuracy : 42.730000000000004%\n",
      "F1_score : 0.4099\n",
      "Cohen Kappa Score : 0.0178 \n",
      "Recall : 0.4273\n",
      "Precision : 0.4036\n",
      "Confusion Matrix : [[ 24   0 109  46]\n",
      " [  3   0   6   4]\n",
      " [ 79   0 400 161]\n",
      " [ 50   0 275 123]]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Fitting SVM on features \n",
      "\n",
      "------------------------ Train Set Metrics------------------------\n",
      "\n",
      "accuracy : 50.0%\n",
      "F1_score : 0.3333\n",
      "Cohen Kappa Score : 0.0 \n",
      "Recall : 0.5\n",
      "Precision : 0.25\n",
      "Confusion Matrix :\n",
      " [[   0    0  574    0]\n",
      " [   0    0   41    0]\n",
      " [   0    0 2048    0]\n",
      " [   0    0 1433    0]]\n",
      "\n",
      "------------------------ Validation Set Metrics------------------------\n",
      "\n",
      "accuracy : 50.0%\n",
      "F1_score : 0.3333\n",
      "Cohen Kappa Score : 0.0 \n",
      "Recall : 0.5\n",
      "Precision : 0.25\n",
      "Confusion Matrix :\n",
      " [[  0   0 143   0]\n",
      " [  0   0  10   0]\n",
      " [  0   0 512   0]\n",
      " [  0   0 359   0]]\n",
      "\n",
      "------------------------ Test Set Metrics------------------------\n",
      "\n",
      "accuracy : 50.0%\n",
      "F1_score : 0.3333\n",
      "Cohen Kappa Score : 0.0 \n",
      "Recall : 0.5\n",
      "Precision : 0.25\n",
      "Confusion Matrix : [[  0   0 179   0]\n",
      " [  0   0  13   0]\n",
      " [  0   0 640   0]\n",
      " [  0   0 448   0]]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Fitting Random Forest Classifier on features \n",
      "\n",
      "------------------------ Train Set Metrics------------------------\n",
      "\n",
      "accuracy : 100.0%\n",
      "F1_score : 1.0\n",
      "Cohen Kappa Score : 1.0 \n",
      "Recall : 1.0\n",
      "Precision : 1.0\n",
      "Confusion Matrix :\n",
      " [[ 574    0    0    0]\n",
      " [   0   41    0    0]\n",
      " [   0    0 2048    0]\n",
      " [   0    0    0 1433]]\n",
      "\n",
      "------------------------ Validation Set Metrics------------------------\n",
      "\n",
      "accuracy : 43.65%\n",
      "F1_score : 0.4066\n",
      "Cohen Kappa Score : -0.0028 \n",
      "Recall : 0.4365\n",
      "Precision : 0.3948\n",
      "Confusion Matrix :\n",
      " [[  7   0 101  35]\n",
      " [  1   0   7   2]\n",
      " [ 23   0 324 165]\n",
      " [ 13   0 230 116]]\n",
      "\n",
      "------------------------ Test Set Metrics------------------------\n",
      "\n",
      "accuracy : 46.02%\n",
      "F1_score : 0.4321\n",
      "Cohen Kappa Score : 0.0444 \n",
      "Recall : 0.4602\n",
      "Precision : 0.4219\n",
      "Confusion Matrix : [[ 13   0 115  51]\n",
      " [  0   0   9   4]\n",
      " [ 36   0 421 183]\n",
      " [ 18   0 275 155]]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Fitting AdaBoost Classifier on features \n",
      "\n",
      "------------------------ Train Set Metrics------------------------\n",
      "\n",
      "accuracy : 49.58%\n",
      "F1_score : 0.3861\n",
      "Cohen Kappa Score : 0.0212 \n",
      "Recall : 0.4958\n",
      "Precision : 0.4415\n",
      "Confusion Matrix :\n",
      " [[   3    0  512   59]\n",
      " [   0    1   37    3]\n",
      " [   3    0 1877  168]\n",
      " [   3    2 1278  150]]\n",
      "\n",
      "------------------------ Validation Set Metrics------------------------\n",
      "\n",
      "accuracy : 49.51%\n",
      "F1_score : 0.3884\n",
      "Cohen Kappa Score : 0.0203 \n",
      "Recall : 0.4951\n",
      "Precision : 0.3932\n",
      "Confusion Matrix :\n",
      " [[  0   0 128  15]\n",
      " [  0   0   9   1]\n",
      " [  0   0 465  47]\n",
      " [  0   0 317  42]]\n",
      "\n",
      "------------------------ Test Set Metrics------------------------\n",
      "\n",
      "accuracy : 49.45%\n",
      "F1_score : 0.3866\n",
      "Cohen Kappa Score : 0.02 \n",
      "Recall : 0.4945\n",
      "Precision : 0.3925\n",
      "Confusion Matrix : [[  0   1 158  20]\n",
      " [  0   1  10   2]\n",
      " [  0   0 583  57]\n",
      " [  0   0 399  49]]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Fitting XGB Classifier on features \n",
      "[12:53:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "------------------------ Train Set Metrics------------------------\n",
      "\n",
      "accuracy : 91.89%\n",
      "F1_score : 0.9171\n",
      "Cohen Kappa Score : 0.8626 \n",
      "Recall : 0.9189\n",
      "Precision : 0.9257\n",
      "Confusion Matrix :\n",
      " [[ 414    0  129   31]\n",
      " [   0   41    0    0]\n",
      " [   1    0 2030   17]\n",
      " [   1    0  153 1279]]\n",
      "\n",
      "------------------------ Validation Set Metrics------------------------\n",
      "\n",
      "accuracy : 47.56%\n",
      "F1_score : 0.4377\n",
      "Cohen Kappa Score : 0.0533 \n",
      "Recall : 0.4756\n",
      "Precision : 0.4345\n",
      "Confusion Matrix :\n",
      " [[  7   0 100  36]\n",
      " [  0   0   7   3]\n",
      " [ 13   0 358 141]\n",
      " [  8   0 229 122]]\n",
      "\n",
      "------------------------ Test Set Metrics------------------------\n",
      "\n",
      "accuracy : 46.64%\n",
      "F1_score : 0.4257\n",
      "Cohen Kappa Score : 0.035 \n",
      "Recall : 0.4664\n",
      "Precision : 0.4201\n",
      "Confusion Matrix : [[  8   0 113  58]\n",
      " [  0   0   6   7]\n",
      " [ 18   0 453 169]\n",
      " [  8   0 304 136]]\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_comparator(x_train_acc,y_train_acc,x_val_acc,y_val_acc,X_test,y_test,classifier=zipped_clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
