{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required Libraries\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import glob\n",
    "import skimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from tqdm import tqdm\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sn.set()\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from time import time\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score,f1_score,recall_score,cohen_kappa_score,precision_score\n",
    "from sklearn.utils import compute_class_weight\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelBinarizer, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNeighborsClassifier\n",
    "from sklearn.svm import SVC # SVM\n",
    "from sklearn.ensemble import RandomForestClassifier # RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier # AdaBoostClassifier\n",
    "from xgboost import XGBClassifier # XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications.vgg16 import VGG16 # VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19 # VGG19\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50 # ResNet50\n",
    "from tensorflow.keras.applications import ResNet101 # ResNet 101\n",
    "from tensorflow.keras.applications.xception import Xception # Xception\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet # MobileNet\n",
    "from tensorflow.keras.applications.densenet import DenseNet169 # DenseNet169\n",
    "from tensorflow.keras.applications.densenet import DenseNet121 # DenseNet121\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 # MobileNetV2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 # InceptionV3\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Flatten, Activation, GlobalAveragePooling2D,Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(path):\n",
    "    '''\n",
    "        parameters\n",
    "        ----------\n",
    "        path : input path of the images\n",
    "        \n",
    "        returns\n",
    "        -------\n",
    "        loadedImages : list of loaded images \n",
    "    '''\n",
    "    sample = []\n",
    "    \n",
    "    for filename in glob.glob(path):\n",
    "        \n",
    "        img = cv2.imread(filename)\n",
    "        img = skimage.transform.resize(img, (224, 224, 3))\n",
    "        IMG = np.array(img)\n",
    "        sample.append(IMG)\n",
    "        \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path1 = 'train/NonDemented/*.jpg' \n",
    "train_path2 = 'train/VeryMildDemented/*.jpg'\n",
    "train_path3 = 'train/MildDemented/*.jpg'\n",
    "train_path4 = 'train/ModerateDemented/*.jpg'\n",
    "\n",
    "test_path1 = 'test/NonDemented/*.jpg' \n",
    "test_path2 = 'test/VeryMildDemented/*.jpg'\n",
    "test_path3 = 'test/MildDemented/*.jpg'\n",
    "test_path4 = 'test/ModerateDemented/*.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ND = loadImages(train_path1)\n",
    "train_VMD = loadImages(train_path2)\n",
    "train_MID = loadImages(train_path3)\n",
    "train_MOD = loadImages(train_path4)\n",
    "\n",
    "test_ND = loadImages(test_path1)\n",
    "test_VMD = loadImages(test_path2)\n",
    "test_MID = loadImages(test_path3)\n",
    "test_MOD = loadImages(test_path4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% CREATION OF DATASETS\n",
    "\n",
    "df_train_ND = pd.DataFrame({'image':train_ND, 'label': 'ND'})\n",
    "df_train_VMD = pd.DataFrame({'image':train_VMD, 'label': 'VMD'})\n",
    "df_train_MID = pd.DataFrame({'image':train_MID, 'label': 'MID'})\n",
    "df_train_MOD = pd.DataFrame({'image':train_MOD, 'label': 'MOD'})\n",
    "\n",
    "df_test_ND = pd.DataFrame({'image':test_ND, 'label': 'ND'})\n",
    "df_test_VMD = pd.DataFrame({'image':test_VMD, 'label': 'VMD'})\n",
    "df_test_MID = pd.DataFrame({'image':test_MID, 'label': 'MID'})\n",
    "df_test_MOD = pd.DataFrame({'image':test_MOD, 'label': 'MOD'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire data size: (6400, 2)\n"
     ]
    }
   ],
   "source": [
    "final_data = [df_train_ND, df_train_VMD, df_train_MID, df_train_MOD, df_test_ND, df_test_VMD, df_test_MID, df_test_MOD]\n",
    "final_data = pd.concat(final_data)\n",
    "\n",
    "print(\"Entire data size:\",final_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% TRAIN LABEL SEPARATION\n",
    "\n",
    "train_data = final_data['image']\n",
    "labels = final_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels Count: Counter({'ND': 3200, 'VMD': 2240, 'MID': 896, 'MOD': 64})\n"
     ]
    }
   ],
   "source": [
    "#%% LOOKING AT THE AMOUNT OF ITEMS PER CLASS \n",
    "\n",
    "print(\"Labels Count:\",Counter(np.array(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#%% ENCODING THE LABELS\n",
    "onehot = LabelEncoder()\n",
    "labels = onehot.fit_transform(labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length X_train: 5120\n",
      "length y_train: 5120\n",
      "length X_test: 1280\n",
      "length y_test: 1280\n"
     ]
    }
   ],
   "source": [
    "#%% SPLITTING INTO TRAIN AND TEST SET, TRAIN SET WILL BE FURTHER SPLIT INTO TRAIN AND VALIDATION SET\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, labels,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  stratify = labels,\n",
    "                                                  shuffle = True,\n",
    "                                                  random_state = 42)\n",
    "\n",
    "print('length X_train:', len(X_train))\n",
    "print('length y_train:', len(y_train))\n",
    "\n",
    "print('length X_test:',  len(X_test))\n",
    "print('length y_test:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5120, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train= np.empty((len(X_train),X_train[0].shape[0],X_train[0].shape[1],X_train[0].shape[2]))\n",
    "for i,x in enumerate(X_train):\n",
    "    x_train[i]=X_train[i]\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "x_test= np.empty((len(X_test),X_test[0].shape[0],X_test[0].shape[1],X_test[0].shape[2]))\n",
    "for i,x in enumerate(X_test):\n",
    "    x_test[i]=X_test[i]\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG19(include_top=False, weights='imagenet', input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x =  Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024,kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x =  Dropout(0.5)(x)\n",
    "x = Dense(1024,kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x =  Dropout(0.5)(x)\n",
    "x = Dense(1024,kernel_initializer='he_uniform')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x =  Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(4, activation='softmax')(x)\n",
    "\n",
    "model_feat = Model(inputs=base_model.input,outputs=predictions)\n",
    "\n",
    "train_features = model_feat.predict(x_train)\n",
    "test_features=model_feat.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Train and validation accuracy\n",
    "x_train_acc, x_val_acc, y_train_acc, y_val_acc = train_test_split(train_features,y_train,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  stratify = y_train,\n",
    "                                                  shuffle = True,\n",
    "                                                  random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length X_train: 4096\n",
      "length y_train: 4096\n",
      "length X_val: 1024\n",
      "length y_val: 1024\n",
      "length X_test: 1280\n",
      "length y_test: 1280\n"
     ]
    }
   ],
   "source": [
    "X_test,y_test=test_features,y_test\n",
    "\n",
    "print('length X_train:', len(x_train_acc))\n",
    "print('length y_train:', len(y_train_acc))\n",
    "\n",
    "print('length X_val:',  len(x_val_acc))\n",
    "print('length y_val:', len(y_val_acc))\n",
    "\n",
    "print('length X_test:',  len(X_test))\n",
    "print('length y_test:', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_summary(pipeline, X_train, y_train, X_val, y_val,X_test,y_test):\n",
    "    sentiment_fit = pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_train= sentiment_fit.predict(X_train)\n",
    "    y_pred_val = sentiment_fit.predict(X_val)\n",
    "    y_pred_test = sentiment_fit.predict(X_test)\n",
    "    \n",
    "    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)*100\n",
    "    train_precision = np.round(precision_score(y_train, y_pred_train, average='weighted'),4)\n",
    "    train_recall = np.round(recall_score(y_train, y_pred_train, average='weighted'),4)\n",
    "    train_F1 = np.round(f1_score(y_train, y_pred_train, average='weighted'),4)\n",
    "    train_kappa =  np.round(cohen_kappa_score(y_train, y_pred_train),4)\n",
    "    train_confusion_matrix = confusion_matrix(y_train,y_pred_train)\n",
    "    \n",
    "    val_accuracy = np.round(accuracy_score(y_val, y_pred_val),4)*100\n",
    "    val_precision = np.round(precision_score(y_val, y_pred_val, average='weighted'),4)\n",
    "    val_recall = np.round(recall_score(y_val, y_pred_val, average='weighted'),4)\n",
    "    val_F1 = np.round(f1_score(y_val, y_pred_val, average='weighted'),4)\n",
    "    val_kappa =  np.round(cohen_kappa_score(y_val, y_pred_val),4)\n",
    "    val_confusion_matrix = confusion_matrix(y_val,y_pred_val)\n",
    "    \n",
    "    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4)*100\n",
    "    test_precision = np.round(precision_score(y_test, y_pred_test, average='weighted'),4)\n",
    "    test_recall = np.round(recall_score(y_test, y_pred_test, average='weighted'),4)\n",
    "    test_F1 = np.round(f1_score(y_test, y_pred_test, average='weighted'),4)\n",
    "    test_kappa =  np.round(cohen_kappa_score(y_test, y_pred_test),4) \n",
    "    test_confusion_matrix = confusion_matrix(y_test,y_pred_test)\n",
    "    \n",
    "    \n",
    "    print()\n",
    "    print('------------------------ Train Set Metrics------------------------')\n",
    "    print()\n",
    "    print(\"accuracy : {}%\".format(train_accuracy))\n",
    "    print(\"F1_score : {}\".format(train_F1))\n",
    "    print(\"Cohen Kappa Score : {} \".format(train_kappa))\n",
    "    print(\"Recall : {}\".format(train_recall))\n",
    "    print(\"Precision : {}\".format(train_precision))\n",
    "    print(\"Confusion Matrix :\\n {}\".format(train_confusion_matrix))\n",
    "    \n",
    "    print()\n",
    "    print('------------------------ Validation Set Metrics------------------------')\n",
    "    print()\n",
    "    print(\"accuracy : {}%\".format(val_accuracy))\n",
    "    print(\"F1_score : {}\".format(val_F1))\n",
    "    print(\"Cohen Kappa Score : {} \".format(val_kappa))\n",
    "    print(\"Recall : {}\".format(val_recall))\n",
    "    print(\"Precision : {}\".format(val_precision))\n",
    "    print(\"Confusion Matrix :\\n {}\".format(val_confusion_matrix))\n",
    "    \n",
    "    print()\n",
    "    print('------------------------ Test Set Metrics------------------------')\n",
    "    print()\n",
    "    print(\"accuracy : {}%\".format(test_accuracy))\n",
    "    print(\"F1_score : {}\".format(test_F1))\n",
    "    print(\"Cohen Kappa Score : {} \".format(test_kappa))\n",
    "    print(\"Recall : {}\".format(test_recall))\n",
    "    print(\"Precision : {}\".format(test_precision))\n",
    "    print(\"Confusion Matrix : {}\".format(test_confusion_matrix))\n",
    "\n",
    "    print(\"-\"*80)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "        \"K Nearest Neighbour Classifier\",\n",
    "        'SVM',\n",
    "        \"Random Forest Classifier\",\n",
    "        \"AdaBoost Classifier\", \n",
    "        \"XGB Classifier\",\n",
    "         ]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    SVC(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    XGBClassifier(),\n",
    "        ]\n",
    "\n",
    "zipped_clf = zip(names,classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_comparator(X_train,y_train,X_val,y_val,X_test,y_test,classifier=zipped_clf): \n",
    "    result = []\n",
    "    for n,c in classifier:\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('classifier', c)\n",
    "        ])\n",
    "        print(\"Fitting {} on features \".format(n))\n",
    "        #print(c)\n",
    "        classifier_summary(checker_pipeline,X_train, y_train, X_val, y_val,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting K Nearest Neighbour Classifier on features \n",
      "\n",
      "------------------------ Train Set Metrics------------------------\n",
      "\n",
      "accuracy : 63.21%\n",
      "F1_score : 0.6189\n",
      "Cohen Kappa Score : 0.3691 \n",
      "Recall : 0.6321\n",
      "Precision : 0.6299\n",
      "Confusion Matrix :\n",
      " [[ 234    0  262   78]\n",
      " [   6    3   26    6]\n",
      " [ 135    2 1672  239]\n",
      " [ 142    3  608  680]]\n",
      "\n",
      "------------------------ Validation Set Metrics------------------------\n",
      "\n",
      "accuracy : 45.800000000000004%\n",
      "F1_score : 0.4429\n",
      "Cohen Kappa Score : 0.0741 \n",
      "Recall : 0.458\n",
      "Precision : 0.4376\n",
      "Confusion Matrix :\n",
      " [[ 27   0  78  38]\n",
      " [  2   0   7   1]\n",
      " [ 53   1 331 127]\n",
      " [ 43   1 204 111]]\n",
      "\n",
      "------------------------ Test Set Metrics------------------------\n",
      "\n",
      "accuracy : 44.690000000000005%\n",
      "F1_score : 0.4273\n",
      "Cohen Kappa Score : 0.0514 \n",
      "Recall : 0.4469\n",
      "Precision : 0.4246\n",
      "Confusion Matrix : [[ 30   1 111  37]\n",
      " [  5   0   6   2]\n",
      " [ 69   3 423 145]\n",
      " [ 57   2 270 119]]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Fitting SVM on features \n",
      "\n",
      "------------------------ Train Set Metrics------------------------\n",
      "\n",
      "accuracy : 51.85999999999999%\n",
      "F1_score : 0.3951\n",
      "Cohen Kappa Score : 0.0546 \n",
      "Recall : 0.5186\n",
      "Precision : 0.453\n",
      "Confusion Matrix :\n",
      " [[   0    0  528   46]\n",
      " [   0    0   40    1]\n",
      " [   0    0 1983   65]\n",
      " [   0    0 1292  141]]\n",
      "\n",
      "------------------------ Validation Set Metrics------------------------\n",
      "\n",
      "accuracy : 51.559999999999995%\n",
      "F1_score : 0.3883\n",
      "Cohen Kappa Score : 0.0471 \n",
      "Recall : 0.5156\n",
      "Precision : 0.4476\n",
      "Confusion Matrix :\n",
      " [[  0   0 132  11]\n",
      " [  0   0  10   0]\n",
      " [  0   0 497  15]\n",
      " [  0   0 328  31]]\n",
      "\n",
      "------------------------ Test Set Metrics------------------------\n",
      "\n",
      "accuracy : 51.09%\n",
      "F1_score : 0.3758\n",
      "Cohen Kappa Score : 0.035 \n",
      "Recall : 0.5109\n",
      "Precision : 0.4307\n",
      "Confusion Matrix : [[  0   0 168  11]\n",
      " [  0   0  10   3]\n",
      " [  0   0 625  15]\n",
      " [  0   0 419  29]]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Fitting Random Forest Classifier on features \n",
      "\n",
      "------------------------ Train Set Metrics------------------------\n",
      "\n",
      "accuracy : 100.0%\n",
      "F1_score : 1.0\n",
      "Cohen Kappa Score : 1.0 \n",
      "Recall : 1.0\n",
      "Precision : 1.0\n",
      "Confusion Matrix :\n",
      " [[ 574    0    0    0]\n",
      " [   0   41    0    0]\n",
      " [   0    0 2048    0]\n",
      " [   0    0    0 1433]]\n",
      "\n",
      "------------------------ Validation Set Metrics------------------------\n",
      "\n",
      "accuracy : 49.51%\n",
      "F1_score : 0.4738\n",
      "Cohen Kappa Score : 0.1171 \n",
      "Recall : 0.4951\n",
      "Precision : 0.4681\n",
      "Confusion Matrix :\n",
      " [[ 17   0  75  51]\n",
      " [  1   0   7   2]\n",
      " [ 26   0 337 149]\n",
      " [ 13   0 193 153]]\n",
      "\n",
      "------------------------ Test Set Metrics------------------------\n",
      "\n",
      "accuracy : 46.089999999999996%\n",
      "F1_score : 0.431\n",
      "Cohen Kappa Score : 0.0463 \n",
      "Recall : 0.4609\n",
      "Precision : 0.4183\n",
      "Confusion Matrix : [[ 12   0 107  60]\n",
      " [  2   0   3   8]\n",
      " [ 34   1 434 171]\n",
      " [ 23   0 281 144]]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Fitting AdaBoost Classifier on features \n",
      "\n",
      "------------------------ Train Set Metrics------------------------\n",
      "\n",
      "accuracy : 50.56%\n",
      "F1_score : 0.4025\n",
      "Cohen Kappa Score : 0.0445 \n",
      "Recall : 0.5056\n",
      "Precision : 0.4542\n",
      "Confusion Matrix :\n",
      " [[   3    1  496   74]\n",
      " [   0    1   36    4]\n",
      " [   4    1 1878  165]\n",
      " [   3    3 1238  189]]\n",
      "\n",
      "------------------------ Validation Set Metrics------------------------\n",
      "\n",
      "accuracy : 51.370000000000005%\n",
      "F1_score : 0.4158\n",
      "Cohen Kappa Score : 0.0622 \n",
      "Recall : 0.5137\n",
      "Precision : 0.4985\n",
      "Confusion Matrix :\n",
      " [[  1   0 122  20]\n",
      " [  0   0  10   0]\n",
      " [  1   2 469  40]\n",
      " [  0   0 303  56]]\n",
      "\n",
      "------------------------ Test Set Metrics------------------------\n",
      "\n",
      "accuracy : 50.0%\n",
      "F1_score : 0.3952\n",
      "Cohen Kappa Score : 0.0331 \n",
      "Recall : 0.5\n",
      "Precision : 0.4534\n",
      "Confusion Matrix : [[  2   0 156  21]\n",
      " [  0   0  10   3]\n",
      " [  1   0 585  54]\n",
      " [  2   1 392  53]]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Fitting XGB Classifier on features \n",
      "[17:44:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "------------------------ Train Set Metrics------------------------\n",
      "\n",
      "accuracy : 89.97%\n",
      "F1_score : 0.8974\n",
      "Cohen Kappa Score : 0.829 \n",
      "Recall : 0.8997\n",
      "Precision : 0.9102\n",
      "Confusion Matrix :\n",
      " [[ 403    0  136   35]\n",
      " [   0   41    0    0]\n",
      " [   0    0 2028   20]\n",
      " [   0    0  220 1213]]\n",
      "\n",
      "------------------------ Validation Set Metrics------------------------\n",
      "\n",
      "accuracy : 49.41%\n",
      "F1_score : 0.4631\n",
      "Cohen Kappa Score : 0.1014 \n",
      "Recall : 0.4941\n",
      "Precision : 0.456\n",
      "Confusion Matrix :\n",
      " [[ 14   0  84  45]\n",
      " [  1   0   8   1]\n",
      " [ 23   1 369 119]\n",
      " [ 20   0 216 123]]\n",
      "\n",
      "------------------------ Test Set Metrics------------------------\n",
      "\n",
      "accuracy : 48.52%\n",
      "F1_score : 0.4509\n",
      "Cohen Kappa Score : 0.0794 \n",
      "Recall : 0.4852\n",
      "Precision : 0.4457\n",
      "Confusion Matrix : [[ 16   0 109  54]\n",
      " [  0   0  10   3]\n",
      " [ 23   1 461 155]\n",
      " [ 22   0 282 144]]\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_comparator(x_train_acc,y_train_acc,x_val_acc,y_val_acc,X_test,y_test,classifier=zipped_clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
